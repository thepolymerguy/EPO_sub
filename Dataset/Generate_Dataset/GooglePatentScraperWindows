"""
Author: Egheosa Ogbomo
Date: 12th August 2022

Creating a script that can:
1. Download CSVs from Google based on a keyword search, (in function form), where the user defines the keyword to be
used to search for patents in google patents, where the CSV contains bibliographic data concerning the returned patents
from the keyword search.
2. Go through each entry in the downloaded CSV, which should have a link to the individual patent's page on Google
patents, opening the link and extracting the HTML from that page
3. Take the following information from the html in string form and store in a dataframe:
    - Country
    - Whether it is active or not
    - Patent Number
    - Abstract
    - Title
    - PCT Number #TODO
    - Applicants #TODO
    - Filing Dates #TODO
    - Grant Dates #TODO
    - Publication Dates #TODO
    - CPC classifications
4. Sort through entries to the CSV where there is missing information and/or no presence of the target class, to ensure
that we generate as balanced a dataset as possible
5. Convert the formatted dataframe into a CSV and save it
6. Return a count for the number of each class
"""

import time
from bs4 import BeautifulSoup as soup
import requests
import pandas as pd
import os
from os import listdir

"""
Working Directory Should Contain CSVs with patent numbers to use for scraping
If you would like a demonstration, please email e.ogbomo21@imperial.ac.uk
"""

working_dir = 'Path/To/workingdir/'
SampleNumber = 500


############ Renaming all of the Search CSVs to their Keyword Search and removing first row ###################

ClassDataframe = pd.DataFrame(columns=["Abstract", "Application_number", "Title", "Classifications", "Country_Code", "Status"])
D = pd.DataFrame(columns=["Abstract", "Application_number", "Title", "Classifications", "Country_Code", "Status"])

def get_patent_metadata(LINK):
    ########################################### Getting the HTML of the entire page ###########################################
    Response = requests.get(LINK)
    Response_HTML = soup(Response.content, "html.parser")
    #print(Response_HTML)

    ###Getting the abstract from each page
    abstract = Response_HTML.find("div", class_="abstract")
    #print(abstract)

    if abstract == None:
        abstract = 'No Abstract'
        print('No abstract')
    else:
        abstract = abstract.get_text()

    # print(abstract)

    ###########################################Getting the Patent Number###########################################
    title = Response_HTML.find("title")
    if title == None:
        Title = 'No Title'
        print('No Title')
    else:
        title = title.get_text()
        title_elements = title.split(" - ")
        Application_number = title_elements[0]
        Title = title_elements[1].replace(" \n     ", "")
    # print(Application_number)
    # print(Title)

    ############################################## Getting the Classification(s) ###########################################
    Unprocessed_Classifications = Response_HTML.find_all(attrs={'itemprop':'Code'})
    #print(Unprocessed_Classifications)
    #print(Unprocessed_Classifications)

    Classifications_Text = []
    Classifications = []

    for x in Unprocessed_Classifications:
        Unprocessed_Classification = x.get_text()
        Classifications_Text.append(Unprocessed_Classification)

        if Unprocessed_Classifications == None:
            break
        else:
            Classifications = [Classifications_Text[-1]]
            Index = 0
            while Index < len(Classifications_Text) - 1:
                if int(len(Classifications_Text[int(Index)+1])) < int(len(Classifications_Text[Index])):
                    Classifications.append(Classifications_Text[Index])
                Index += 1
    #print(Classifications)

    ############################################## Getting the Patent Country Code ###########################################
    Country_Code = Response_HTML.find(attrs={'itemprop':'countryCode'}).get_text()
    #print(Country_Code)

    ################################## Getting Current Status of the Patent ###########################################
    Status = Response_HTML.find(attrs={'itemprop':'status'})
    if Status == None:
        Status = 'Status Unknown'
        print('Status Unknown')
    else:
        Status = Status.get_text()

    return abstract, Application_number, Title, Classifications, Country_Code, Status

####### Downloading Google Patents for Web Scraping ###########################

for csv in os.listdir(working_dir):
    file = pd.read_csv(f'{working_dir}{csv}')
    for x in file.iloc[1:, 0].head(SampleNumber):
         string_link = str(x)
         if string_link.endswith('en') == False:
             break
         else:
             print(x)
             abstract, Application_number, Title, Classifications, Country_Code, Status = get_patent_metadata(x)
         if abstract == 'No Abstract':
             continue
         elif Classifications == []:
             continue
         else:
             Info = [abstract, Application_number, Title, Classifications, Country_Code, Status]
             D.loc[len(D)] = Info
             ClassDataframe.loc[len(ClassDataframe)] = Info

    ClassDataframe.to_csv(f"path/to/workingdir/TrainingDataset/Processed_{csv}", index=False)

D.to_csv(f"path/to/working/LargeDataset.csv", index=False)
